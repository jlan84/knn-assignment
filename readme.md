## Decision Trees and k Nearest Neighbors

Today we will be playing with non-parametric models. Non-parametric models have a flexible number of parameters (unlike logistic regression, which is parametric).

We will be using two machine learning models: **Decision Trees** and **k Nearest Neighbors**.


### Lecture Notes

Notes on [decision trees and kNN](lecture.md)

### Assignment

You will be implementing decision trees and kNN with [this assignment](pair.md).

### Goals

* Train vs. Test
* Non-parametric models
* CART algorithm
* Conditional Independence
* Maximum Likelihood
* Conditional Probability Table
* Gini coefficient vs. information gain 

### Reading

* [Parametric vs Non-Parametric models](http://www.statsblogs.com/2014/01/15/machine-learning-lesson-of-the-day-parametric-vs-non-parametric-models/)

#### Decision Trees

* [Applied Data Science](http://columbia-applied-data-science.github.io/appdatasci.pdf): Chapter 9.4 (p. 100 - p. 104)
* Machine Learning in Action: Chapter 3 ([ID3](http://en.wikipedia.org/wiki/ID3_algorithm))
* [scikit-learn docs: Decision Trees](http://scikit-learn.org/stable/modules/tree.html)

#### k Nearest Neighbors (kNN)
* Machine Learning in Action: Chapter 2
* [scikit-learn docs: K Neighbors Classifier](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)


